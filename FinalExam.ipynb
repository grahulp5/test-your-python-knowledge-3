{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Exam (20 marks) - House Office Expenditure Data\n",
    "\n",
    "Members of Congress and Congressional offices receive an annual budget to spend on staff, supplies, transportation, and other expenses. Each quarter, representatives report the recipients of their expenditures. ProPublica compiles these reports into research-ready CSV files. The full data set has already been downloaded for your convenience. The data set includes a readme text file describing the data in more detail, which may be helpful in completing this exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "House Office Expenditure Data\n",
    "\n",
    "Last updated June 4, 2019.\n",
    "\n",
    "https://projects.propublica.org/represent/expenditures\n",
    "\n",
    "Members of the House of Representatives get an annual budget for their Washington and district offices, but how they spend it is up to them. There are some rules: It can’t be used for personal or campaign expenses, and there is no reserve source of money if lawmakers spend all of their allowances.\n",
    "\n",
    "Lawmakers also are required to report the recipients of their office spending, and since 2009 the Sunlight Foundation has been taking the PDF files published by the House and converting them into text files useful for analysis and research. As of November 2016, ProPublica has taken over both the collection and hosting of these files. They can be examined using spreadsheet or database software. \n",
    "\n",
    "__How We Collect This Data__\n",
    "\n",
    "Each quarter we take the report published by the House and generate two text files: One contains summary information for each office and category of spending (some examples include “Personnel Compensation” and “Travel”), and the other contains details of each recipient of office spending and its purpose. Note that the data has not been standardized (meaning that \"AT&T\" might also appear as \"A.T.&T.\"), so simple aggregation on the recipient could result in multiple totals for the same individual or entity, depending on the spelling. Individual recipients can be paid by more than one office or lawmaker in some cases.\n",
    "\n",
    "Most of the records are connected to lawmaker offices, but the files also contain spending records for House committees and administrative offices, in addition to leadership organizations such as the Speaker of the House and the two parties' leaders.\n",
    "\n",
    "Before you dig into the data to find out how the House spends its money, you may find it useful to check out this post (https://www.propublica.org/article/update-on-house-disbursements-a-few-notes-on-how-to-use-the-data) from a Sunlight training webinar that explains discrepancies with how the House reports lawmakers' spending, and gives guidelines on how to use the data.\n",
    "\n",
    "\n",
    "## Data Dictionary\n",
    "\n",
    "\n",
    "__Summary files__\n",
    "\n",
    "    BIOGUIDE_ID – the official ID of members of the House (http://bioguide.congress.gov/biosearch/biosearch.asp)\n",
    "    OFFICE – the name of the House office\n",
    "    YEAR – the calendar year\n",
    "    QUARTER – the quarter of the year\n",
    "    CATEGORY – broad description of spending\n",
    "    YTD – year to date amount spent by office in that category \n",
    "    AMOUNT – amount spent by office in that category in quarter\n",
    "\n",
    "__Detail files__\n",
    "\n",
    "    Has BIOGUIDE, OFFICE, QUARTER, YEAR, CATEGORY, AMOUNT, plus the following:\n",
    "\n",
    "    PAYEE – name of recipient\n",
    "    PURPOSE – specific purpose of spending\n",
    "    DATE -  date of payment (optional)\n",
    "    START DATE – beginning of period which payment covers\n",
    "    END DATE – end of period which payment covers\n",
    "    TRANSCODE – House transaction code\n",
    "    TRANSCODELONG – description of House transaction code\n",
    "    RECORDID – House record number\n",
    "    RECIP (orig.) - original (non standardized) recipient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 (2 marks)\n",
    "\n",
    "Import the necessary libraries and read each of the following files from the included __data__ folder as a Dataframe: \n",
    "\n",
    "- 2010Q1-house-disburse-detail.csv\n",
    "- 2010Q1-house-disburse-summary.csv\n",
    "- 2010Q2-house-disburse-detail.csv\n",
    "- 2010Q2-house-disburse-summary.csv\n",
    "- 2010Q3-house-disburse-detail.csv\n",
    "- 2010Q3-house-disburse-summary.csv\n",
    "- 2010Q4-house-disburse-detail.csv\n",
    "- 2010Q4-house-disburse-summary.csv\n",
    "- 2011Q1-house-disburse-detail.csv\n",
    "- 2011Q1-house-disburse-summary.csv\n",
    "- 2011Q2-house-disburse-detail.csv\n",
    "- 2011Q2-house-disburse-summary.csv\n",
    "- 2011Q3-house-disburse-detail.csv\n",
    "- 2011Q3-house-disburse-summary.csv\n",
    "- 2011Q4-house-disburse-detail.csv\n",
    "- 2011Q4-house-disburse-summary.csv\n",
    "- 2012Q1-house-disburse-detail.csv\n",
    "- 2012Q1-house-disburse-summary.csv\n",
    "- 2012Q2-house-disburse-detail.csv\n",
    "- 2012Q2-house-disburse-summary.csv\n",
    "- 2012Q3-house-disburse-detail.csv\n",
    "- 2012Q3-house-disburse-summary.csv\n",
    "- 2012Q4-house-disburse-detail.csv\n",
    "- 2012Q4-house-disburse-summary.csv\n",
    "- 2013Q1-house-disburse-detail.csv\n",
    "- 2013Q1-house-disburse-summary.csv\n",
    "- 2013Q2-house-disburse-detail.csv\n",
    "- 2013Q2-house-disburse-summary.csv\n",
    "- 2013Q3-house-disburse-detail.csv\n",
    "- 2013Q3-house-disburse-summary.csv\n",
    "- 2013Q4-house-disburse-detail.csv\n",
    "- 2013Q4-house-disburse-summary.csv\n",
    "- 2014Q1-house-disburse-detail.csv\n",
    "- 2014Q1-house-disburse-summary.csv\n",
    "- 2014Q2-house-disburse-detail.csv\n",
    "- 2014Q2-house-disburse-summary.csv\n",
    "- 2014Q3-house-disburse-detail.csv\n",
    "- 2014Q3-house-disburse-summary.csv\n",
    "- 2014Q4-house-disburse-detail.csv\n",
    "- 2014Q4-house-disburse-summary.csv\n",
    "- 2015Q1-house-disburse-detail.csv\n",
    "- 2015Q1-house-disburse-summary.csv\n",
    "- 2015Q2-house-disburse-detail.csv\n",
    "- 2015Q2-house-disburse-summary.csv\n",
    "- 2015Q3-house-disburse-detail.csv\n",
    "- 2015Q3-house-disburse-summary.csv\n",
    "- 2015Q4-house-disburse-detail.csv\n",
    "- 2015Q4-house-disburse-summary.csv\n",
    "- 2016Q1-house-disburse-detail.csv\n",
    "- 2016Q1-house-disburse-summary.csv\n",
    "- 2016Q2-house-disburse-detail.csv\n",
    "- 2016Q2-house-disburse-summary.csv\n",
    "- 2016Q3-house-disburse-detail.csv\n",
    "- 2016Q3-house-disburse-summary.csv\n",
    "- 2016Q4-house-disburse-detail.csv\n",
    "- 2016Q4-house-disburse-summary.csv\n",
    "- 2017Q1-house-disburse-detail.csv\n",
    "- 2017Q1-house-disburse-summary.csv\n",
    "- 2017Q2-house-disburse-detail.csv\n",
    "- 2017Q2-house-disburse-summary.csv\n",
    "- 2017Q3-house-disburse-detail.csv\n",
    "- 2017Q3-house-disburse-summary.csv\n",
    "- 2017Q4-house-disburse-detail.csv\n",
    "- 2017Q4-house-disburse-summary.csv\n",
    "\n",
    "As you can begin to realize, there are a total of 64 files and each needs to be read into a separate Dataframe. Therefore the manual approach of storing each into a separate variable such as __df1__, __df2__ etc is no longer feasible.\n",
    "\n",
    "What you should do instead is, use a suitable data structure to create a data store. Once you have done that, you should be able to access your Dataframes as follows:\n",
    "\n",
    "- `data['detail']['Y2010Q1']` represents the Dataframe for `2010Q1-house-disburse-detail.csv`\n",
    "- `data['summary']['Y2010Q1']` represents the Dataframe for `2010Q1-house-disburse-summary.csv`\n",
    "\n",
    "... and so on.\n",
    "\n",
    "Such a data store would allow you to use a consistent naming scheme for both the `detail` and `summary` Dataframes. That is:\n",
    "\n",
    "For both the files `2010Q1-house-disburse-detail.csv` and `2010Q1-house-disburse-summary.csv`, you use the same name __Y2010Q1__ for your Dataframe.\n",
    "\n",
    "Similarly, for both the files `2010Q2-house-disburse-detail.csv` and `2010Q2-house-disburse-summary.csv`, you use the same name __Y2010Q2__ for your Dataframe and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Hint:</u> You would need to use the following additional library:\n",
    "\n",
    "__import__ glob\n",
    "\n",
    "And then use the code `path = 'data'` and `glob.glob(path + \"/*.csv\")` to read all the files from the __data__ folder. Also, you would need the `encoding='unicode_escape'` to read the files properly.\n",
    "\n",
    "You would also need to come up with suitable logic and code so that the file `2010Q1-house-disburse-detail.csv` gets read into the Dataframe `data['detail']['Y2010Q1']` while `2010Q1-house-disburse-summary.csv` gets read into the Dataframe `data['summary']['Y2010Q1']` and so on (shouldn't take more than 8-10 lines of code).\n",
    "\n",
    "In case you get a warning for the first file, ignore it as it's just the BIOGUIDE_ID column or use `low_memory=False` to fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code below this comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (1 mark)\n",
    "\n",
    "Some Dataframes may have one or more column names with extra spaces at either end. Write code to detect such Dataframes and correct the column names before moving ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code below this comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (3 marks)\n",
    "\n",
    "1. Combine all the `'detail'` Dataframes from your store vertically into a single Dataframe named __df_detail__ based on common columns across all the Dataframes.\n",
    "2. Make sure the sort order of the common column names is the same as that in the first Dataframe `data['detail']['Y2010Q1']`.\n",
    "3. Once you have done that, confirm whether the total number of rows for all the Dataframes is equal to the number of rows for the combined Dataframe __df_detail__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code below this comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 (3 marks)\n",
    "\n",
    "1. Similarly, combine all the `'summary'` Dataframes from your store vertically into a single Dataframe named __df_summary__ based on common columns across all the Dataframes.\n",
    "2. Make sure the sort order of the common column names is the same as that in the first Dataframe `data['summary']['Y2010Q1']`. \n",
    "3. Once you have done that, confirm whether the total number of rows for all the Dataframes is equal to the number of rows for the combined Dataframe __df_summary__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code below this comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 (1.5 marks)\n",
    "\n",
    "1. Find missing values in the __df_detail__ Dataframe and report the sum of missing values for all the columns in __df_detail__ as a single number. \n",
    "2. Note that the combined Dataframe __df_detail__ would have some columns that have 3 spaces `'   '` stored as a string which came from the 2017 data files and basically indicate a missing value. Convert these values to __NaN__ so they are correctly recognized as missing values.\n",
    "3. Then update the count of missing values again as a single number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code below this comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 (1.5 marks)\n",
    "\n",
    "Specify the right data type for the following columns in __df_detail__ for further analysis:\n",
    "\n",
    "- `'AMOUNT'`\n",
    "- `'START DATE'`\n",
    "- `'END DATE'`\n",
    "\n",
    "The __AMOUNT__ column needs to be converted into a numeric column (i.e. one with floating point values). While the columns __START DATE__ and __END DATE__ need to be converted into DateTime type objects. Make sure you handle the commas in the __AMOUNT__ column before converting it into numeric type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Hint:</u> If you get any errors, try using `errors=\"coerce\"` and that should do the trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code below this comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOW ANSWER THE FOLLOWING QUESTIONS.\n",
    "\n",
    "All questions pertain to the __df_detail__ Dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Note:</u> The detailed instructions you have received in this exam so far regarding transformations were for your convenience only. In a real-world Data Science challenge, you would only be asked the questions (such as the ones to follow) and then it's up to you to do whatever transformations need to be done to answer those questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 (1 mark)\n",
    "\n",
    "What is the total of all the payments in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code below this comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 (2 marks)\n",
    "\n",
    "What was the average annual expenditure with a __START DATE__ date between January 1, 2010 and December 31, 2016 (inclusive)? Only consider payments with strictly positive amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code below this comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9 (2 marks)\n",
    "\n",
    "What was the highest average staff salary among all representatives in 2016? Assume staff size is equal to the number of unique payees in the `'PERSONNEL COMPENSATION'` category for each representative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code below this comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10 (3 marks)\n",
    "\n",
    "1. Find the __OFFICE__ with the highest total expenditures with a __START DATE__ in 2016.\n",
    "2. For this office, find the __PURPOSE__ that accounts for the highest total expenditures.\n",
    "3. What fraction of the total expenditures (all records, all offices) with a __START DATE__ in 2016 do these expenditures amount to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code below this comment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
