{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8p-cpLrH6OV"
      },
      "source": [
        "# Final Exam (20 marks) - House Office Expenditure Data\n",
        "\n",
        "Members of Congress and Congressional offices receive an annual budget to spend on staff, supplies, transportation, and other expenses. Each quarter, representatives report the recipients of their expenditures. ProPublica compiles these reports into research-ready CSV files. The full data set has already been downloaded for your convenience. The data set includes a readme text file describing the data in more detail, which may be helpful in completing this exam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8GDdrpbH6OY"
      },
      "source": [
        "## Data Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsemoAijH6OZ"
      },
      "source": [
        "House Office Expenditure Data\n",
        "\n",
        "Last updated June 4, 2019.\n",
        "\n",
        "https://projects.propublica.org/represent/expenditures\n",
        "\n",
        "Members of the House of Representatives get an annual budget for their Washington and district offices, but how they spend it is up to them. There are some rules: It can’t be used for personal or campaign expenses, and there is no reserve source of money if lawmakers spend all of their allowances.\n",
        "\n",
        "Lawmakers also are required to report the recipients of their office spending, and since 2009 the Sunlight Foundation has been taking the PDF files published by the House and converting them into text files useful for analysis and research. As of November 2016, ProPublica has taken over both the collection and hosting of these files. They can be examined using spreadsheet or database software.\n",
        "\n",
        "__How We Collect This Data__\n",
        "\n",
        "Each quarter we take the report published by the House and generate two text files: One contains summary information for each office and category of spending (some examples include “Personnel Compensation” and “Travel”), and the other contains details of each recipient of office spending and its purpose. Note that the data has not been standardized (meaning that \"AT&T\" might also appear as \"A.T.&T.\"), so simple aggregation on the recipient could result in multiple totals for the same individual or entity, depending on the spelling. Individual recipients can be paid by more than one office or lawmaker in some cases.\n",
        "\n",
        "Most of the records are connected to lawmaker offices, but the files also contain spending records for House committees and administrative offices, in addition to leadership organizations such as the Speaker of the House and the two parties' leaders.\n",
        "\n",
        "Before you dig into the data to find out how the House spends its money, you may find it useful to check out this post (https://www.propublica.org/article/update-on-house-disbursements-a-few-notes-on-how-to-use-the-data) from a Sunlight training webinar that explains discrepancies with how the House reports lawmakers' spending, and gives guidelines on how to use the data.\n",
        "\n",
        "\n",
        "## Data Dictionary\n",
        "\n",
        "\n",
        "__Summary files__\n",
        "\n",
        "    BIOGUIDE_ID – the official ID of members of the House (http://bioguide.congress.gov/biosearch/biosearch.asp)\n",
        "    OFFICE – the name of the House office\n",
        "    YEAR – the calendar year\n",
        "    QUARTER – the quarter of the year\n",
        "    CATEGORY – broad description of spending\n",
        "    YTD – year to date amount spent by office in that category\n",
        "    AMOUNT – amount spent by office in that category in quarter\n",
        "\n",
        "__Detail files__\n",
        "\n",
        "    Has BIOGUIDE, OFFICE, QUARTER, YEAR, CATEGORY, AMOUNT, plus the following:\n",
        "\n",
        "    PAYEE – name of recipient\n",
        "    PURPOSE – specific purpose of spending\n",
        "    DATE -  date of payment (optional)\n",
        "    START DATE – beginning of period which payment covers\n",
        "    END DATE – end of period which payment covers\n",
        "    TRANSCODE – House transaction code\n",
        "    TRANSCODELONG – description of House transaction code\n",
        "    RECORDID – House record number\n",
        "    RECIP (orig.) - original (non standardized) recipient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5X5obXSH6OZ"
      },
      "source": [
        "### Task 1 (2 marks)\n",
        "\n",
        "Import the necessary libraries and read each of the following files from the included __data__ folder as a Dataframe:\n",
        "\n",
        "- 2010Q1-house-disburse-detail.csv\n",
        "- 2010Q1-house-disburse-summary.csv\n",
        "- 2010Q2-house-disburse-detail.csv\n",
        "- 2010Q2-house-disburse-summary.csv\n",
        "- 2010Q3-house-disburse-detail.csv\n",
        "- 2010Q3-house-disburse-summary.csv\n",
        "- 2010Q4-house-disburse-detail.csv\n",
        "- 2010Q4-house-disburse-summary.csv\n",
        "- 2011Q1-house-disburse-detail.csv\n",
        "- 2011Q1-house-disburse-summary.csv\n",
        "- 2011Q2-house-disburse-detail.csv\n",
        "- 2011Q2-house-disburse-summary.csv\n",
        "- 2011Q3-house-disburse-detail.csv\n",
        "- 2011Q3-house-disburse-summary.csv\n",
        "- 2011Q4-house-disburse-detail.csv\n",
        "- 2011Q4-house-disburse-summary.csv\n",
        "- 2012Q1-house-disburse-detail.csv\n",
        "- 2012Q1-house-disburse-summary.csv\n",
        "- 2012Q2-house-disburse-detail.csv\n",
        "- 2012Q2-house-disburse-summary.csv\n",
        "- 2012Q3-house-disburse-detail.csv\n",
        "- 2012Q3-house-disburse-summary.csv\n",
        "- 2012Q4-house-disburse-detail.csv\n",
        "- 2012Q4-house-disburse-summary.csv\n",
        "- 2013Q1-house-disburse-detail.csv\n",
        "- 2013Q1-house-disburse-summary.csv\n",
        "- 2013Q2-house-disburse-detail.csv\n",
        "- 2013Q2-house-disburse-summary.csv\n",
        "- 2013Q3-house-disburse-detail.csv\n",
        "- 2013Q3-house-disburse-summary.csv\n",
        "- 2013Q4-house-disburse-detail.csv\n",
        "- 2013Q4-house-disburse-summary.csv\n",
        "- 2014Q1-house-disburse-detail.csv\n",
        "- 2014Q1-house-disburse-summary.csv\n",
        "- 2014Q2-house-disburse-detail.csv\n",
        "- 2014Q2-house-disburse-summary.csv\n",
        "- 2014Q3-house-disburse-detail.csv\n",
        "- 2014Q3-house-disburse-summary.csv\n",
        "- 2014Q4-house-disburse-detail.csv\n",
        "- 2014Q4-house-disburse-summary.csv\n",
        "- 2015Q1-house-disburse-detail.csv\n",
        "- 2015Q1-house-disburse-summary.csv\n",
        "- 2015Q2-house-disburse-detail.csv\n",
        "- 2015Q2-house-disburse-summary.csv\n",
        "- 2015Q3-house-disburse-detail.csv\n",
        "- 2015Q3-house-disburse-summary.csv\n",
        "- 2015Q4-house-disburse-detail.csv\n",
        "- 2015Q4-house-disburse-summary.csv\n",
        "- 2016Q1-house-disburse-detail.csv\n",
        "- 2016Q1-house-disburse-summary.csv\n",
        "- 2016Q2-house-disburse-detail.csv\n",
        "- 2016Q2-house-disburse-summary.csv\n",
        "- 2016Q3-house-disburse-detail.csv\n",
        "- 2016Q3-house-disburse-summary.csv\n",
        "- 2016Q4-house-disburse-detail.csv\n",
        "- 2016Q4-house-disburse-summary.csv\n",
        "- 2017Q1-house-disburse-detail.csv\n",
        "- 2017Q1-house-disburse-summary.csv\n",
        "- 2017Q2-house-disburse-detail.csv\n",
        "- 2017Q2-house-disburse-summary.csv\n",
        "- 2017Q3-house-disburse-detail.csv\n",
        "- 2017Q3-house-disburse-summary.csv\n",
        "- 2017Q4-house-disburse-detail.csv\n",
        "- 2017Q4-house-disburse-summary.csv\n",
        "\n",
        "As you can begin to realize, there are a total of 64 files and each needs to be read into a separate Dataframe. Therefore the manual approach of storing each into a separate variable such as __df1__, __df2__ etc is no longer feasible.\n",
        "\n",
        "What you should do instead is, use a suitable data structure to create a data store. Once you have done that, you should be able to access your Dataframes as follows:\n",
        "\n",
        "- `data['detail']['Y2010Q1']` represents the Dataframe for `2010Q1-house-disburse-detail.csv`\n",
        "- `data['summary']['Y2010Q1']` represents the Dataframe for `2010Q1-house-disburse-summary.csv`\n",
        "\n",
        "... and so on.\n",
        "\n",
        "Such a data store would allow you to use a consistent naming scheme for both the `detail` and `summary` Dataframes. That is:\n",
        "\n",
        "For both the files `2010Q1-house-disburse-detail.csv` and `2010Q1-house-disburse-summary.csv`, you use the same name __Y2010Q1__ for your Dataframe.\n",
        "\n",
        "Similarly, for both the files `2010Q2-house-disburse-detail.csv` and `2010Q2-house-disburse-summary.csv`, you use the same name __Y2010Q2__ for your Dataframe and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6bdfQGnH6Oa"
      },
      "source": [
        "<u>Hint:</u> You would need to use the following additional library:\n",
        "\n",
        "__import__ glob\n",
        "\n",
        "And then use the code `path = 'data'` and `glob.glob(path + \"/*.csv\")` to read all the files from the __data__ folder. Also, you would need the `encoding='unicode_escape'` to read the files properly.\n",
        "\n",
        "You would also need to come up with suitable logic and code so that the file `2010Q1-house-disburse-detail.csv` gets read into the Dataframe `data['detail']['Y2010Q1']` while `2010Q1-house-disburse-summary.csv` gets read into the Dataframe `data['summary']['Y2010Q1']` and so on (shouldn't take more than 8-10 lines of code).\n",
        "\n",
        "In case you get a warning for the first file, ignore it as it's just the BIOGUIDE_ID column or use `low_memory=False` to fix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG_btA4ZH6Oa",
        "outputId": "c4a77f55-ce86-424f-e0ed-1a783e5b09fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       BIOGUIDE_ID                   OFFICE QUARTER  \\\n",
            "0              NaN           COMMUNICATIONS  2010Q1   \n",
            "1              NaN           COMMUNICATIONS  2010Q1   \n",
            "2              NaN           COMMUNICATIONS  2010Q1   \n",
            "3              NaN           COMMUNICATIONS  2010Q1   \n",
            "4              NaN           COMMUNICATIONS  2010Q1   \n",
            "...            ...                      ...     ...   \n",
            "132795         NaN  EMERGENCY RESPONSE TEAM  2010Q1   \n",
            "132796         NaN  EMERGENCY RESPONSE TEAM  2010Q1   \n",
            "132797         NaN  EMERGENCY RESPONSE TEAM  2010Q1   \n",
            "132798         NaN  EMERGENCY RESPONSE TEAM  2010Q1   \n",
            "132799         NaN  EMERGENCY RESPONSE TEAM  2010Q1   \n",
            "\n",
            "                              CATEGORY  DATE  \\\n",
            "0                       OTHER SERVICES   NaN   \n",
            "1               SUPPLIES AND MATERIALS   NaN   \n",
            "2               SUPPLIES AND MATERIALS   NaN   \n",
            "3               SUPPLIES AND MATERIALS   NaN   \n",
            "4               SUPPLIES AND MATERIALS   NaN   \n",
            "...                                ...   ...   \n",
            "132795                          TRAVEL   NaN   \n",
            "132796                          TRAVEL   NaN   \n",
            "132797  RENT, COMMUNICATION, UTILITIES   NaN   \n",
            "132798  RENT, COMMUNICATION, UTILITIES   NaN   \n",
            "132799                  OTHER SERVICES   NaN   \n",
            "\n",
            "                                                    PAYEE START DATE  \\\n",
            "0       03Â­10       P2 MFP0003226                    ...   03/02/10   \n",
            "1            02Â­05       P2    MFP0003219       ALLSTEEL   11/28/09   \n",
            "2       03Â­05       P2    OSM42304         CDW GOVERN...   12/21/09   \n",
            "3             03Â­05       P2    OSM42304              DO   12/21/09   \n",
            "4             03Â­05       P2    OSM42304              DO   12/21/09   \n",
            "...                                                   ...        ...   \n",
            "132795  03Â­29   P1   10A54000097               KEVIN ...   02/14/10   \n",
            "132796  03Â­29   P1   10A54000096               PAUL J...   02/14/10   \n",
            "132797        03Â­07   P1 10A10600093     RICHARD MARTINS   02/14/10   \n",
            "132798         03Â­07   P1 10A10600097     TIMOTHY WRIGHT   02/14/10   \n",
            "132799  03Â­07   P1 10A60200014                 DANIEL...   02/24/10   \n",
            "\n",
            "        END DATE                         PURPOSE  AMOUNT              YEAR  \\\n",
            "0       03/02/10  NON-TECHNOLOGY SERVICE CONTRCT  455.00  FISCAL YEAR 2010   \n",
            "1       11/28/09             HABITATION EXPENSES   47.26  FISCAL YEAR 2010   \n",
            "2       12/21/09         OFFICE SUPPLIES OUTSIDE  250.00  FISCAL YEAR 2010   \n",
            "3       12/21/09         OFFICE SUPPLIES OUTSIDE  436.00  FISCAL YEAR 2010   \n",
            "4       12/21/09         OFFICE SUPPLIES OUTSIDE   37.90  FISCAL YEAR 2010   \n",
            "...          ...                             ...     ...               ...   \n",
            "132795  02/19/10            TRAVEL REIMBURSEMENT  858.00  FISCAL YEAR 2010   \n",
            "132796  02/19/10            TRAVEL REIMBURSEMENT  795.00  FISCAL YEAR 2010   \n",
            "132797  02/19/10      TELECOM SVC, EQUIP & TOLLS    9.95  FISCAL YEAR 2010   \n",
            "132798  02/19/10      TELECOM SVC, EQUIP & TOLLS   19.90  FISCAL YEAR 2010   \n",
            "132799  03/02/10   JANITORIAL & MAINTENANCE SVCS  295.11  FISCAL YEAR 2010   \n",
            "\n",
            "        TRANSCODE  TRANSCODELONG  RECORDID  \\\n",
            "0             NaN            NaN       NaN   \n",
            "1             NaN            NaN       NaN   \n",
            "2             NaN            NaN       NaN   \n",
            "3             NaN            NaN       NaN   \n",
            "4             NaN            NaN       NaN   \n",
            "...           ...            ...       ...   \n",
            "132795        NaN            NaN       NaN   \n",
            "132796        NaN            NaN       NaN   \n",
            "132797        NaN            NaN       NaN   \n",
            "132798        NaN            NaN       NaN   \n",
            "132799        NaN            NaN       NaN   \n",
            "\n",
            "                                            RECIP (orig.)  \n",
            "0       03Â­10       P2 MFP0003226                    ...  \n",
            "1            02Â­05       P2    MFP0003219       ALLSTEEL  \n",
            "2       03Â­05       P2    OSM42304         CDW GOVERN...  \n",
            "3             03Â­05       P2    OSM42304              DO  \n",
            "4             03Â­05       P2    OSM42304              DO  \n",
            "...                                                   ...  \n",
            "132795  03Â­29   P1   10A54000097               KEVIN ...  \n",
            "132796  03Â­29   P1   10A54000096               PAUL J...  \n",
            "132797        03Â­07   P1 10A10600093     RICHARD MARTINS  \n",
            "132798         03Â­07   P1 10A10600097     TIMOTHY WRIGHT  \n",
            "132799  03Â­07   P1 10A60200014                 DANIEL...  \n",
            "\n",
            "[132800 rows x 15 columns]\n",
            "     BIOGUIDE_ID                   OFFICE              YEAR QUARTER  \\\n",
            "0            NaN           COMMUNICATIONS  FISCAL YEAR 2010  2010Q1   \n",
            "1            NaN           COMMUNICATIONS  FISCAL YEAR 2010  2010Q1   \n",
            "2            NaN           COMMUNICATIONS  FISCAL YEAR 2010  2010Q1   \n",
            "3            NaN    OFFICE OF THE SPEAKER  FISCAL YEAR 2010  2010Q1   \n",
            "4            NaN    OFFICE OF THE SPEAKER  FISCAL YEAR 2010  2010Q1   \n",
            "...          ...                      ...               ...     ...   \n",
            "3991         NaN           ALTERNATE SITE  FISCAL YEAR 2010  2010Q1   \n",
            "3992         NaN  EMERGENCY RESPONSE TEAM  FISCAL YEAR 2010  2010Q1   \n",
            "3993         NaN  EMERGENCY RESPONSE TEAM  FISCAL YEAR 2010  2010Q1   \n",
            "3994         NaN  EMERGENCY RESPONSE TEAM  FISCAL YEAR 2010  2010Q1   \n",
            "3995         NaN  EMERGENCY RESPONSE TEAM  FISCAL YEAR 2010  2010Q1   \n",
            "\n",
            "                            CATEGORY           YTD      AMOUNT  \n",
            "0                     OTHER SERVICES      1,755.00      455.00  \n",
            "1             SUPPLIES AND MATERIALS        979.36      771.16  \n",
            "2                          EQUIPMENT     33,815.32   33,767.32  \n",
            "3             PERSONNEL COMPENSATION    447,067.08  226,102.50  \n",
            "4             PERSONNEL COMPENSATION  1,857,385.12  952,771.16  \n",
            "...                              ...           ...         ...  \n",
            "3991                       EQUIPMENT     74,325.40    1,251.48  \n",
            "3992                          TRAVEL     33,344.24   26,539.28  \n",
            "3993  RENT, COMMUNICATION, UTILITIES      4,518.60       29.85  \n",
            "3994                  OTHER SERVICES        295.11      295.11  \n",
            "3995          SUPPLIES AND MATERIALS      1,576.25        0.00  \n",
            "\n",
            "[3996 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "### Write your code below this comment.\n",
        "\n",
        "import pandas as pd\n",
        "import glob\n",
        "import re\n",
        "\n",
        "path = '/content/'\n",
        "files = glob.glob(path + \"/*.csv\")\n",
        "\n",
        "df_1 = {'detail': {}, 'summary': {}}\n",
        "\n",
        "\n",
        "for file in files:\n",
        "    match = re.search(r'(\\d{4}Q\\d)', file)\n",
        "    if match:\n",
        "        year_quarter = match.group(1)\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    data_type = 'detail' if 'detail' in file else 'summary'\n",
        "\n",
        "    key = f'Y{year_quarter}'\n",
        "\n",
        "    df_1[data_type][key] = pd.read_csv(file, encoding='unicode_escape', low_memory=False)\n",
        "\n",
        "print(df_1['detail']['Y2010Q1'])\n",
        "print(df_1['summary']['Y2010Q1'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6_wTfsCH6Ob"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Axmq5HMHH6Oc"
      },
      "source": [
        "### Task 2 (1 mark)\n",
        "\n",
        "Some Dataframes may have one or more column names with extra spaces at either end. Write code to detect such Dataframes and correct the column names before moving ahead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn4Wi-XLH6Oc",
        "outputId": "0cf0636d-77c7-47a3-a6e9-139ecfb257bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       BIOGUIDE_ID                   OFFICE QUARTER  \\\n",
            "0              NaN           COMMUNICATIONS  2010Q1   \n",
            "1              NaN           COMMUNICATIONS  2010Q1   \n",
            "2              NaN           COMMUNICATIONS  2010Q1   \n",
            "3              NaN           COMMUNICATIONS  2010Q1   \n",
            "4              NaN           COMMUNICATIONS  2010Q1   \n",
            "...            ...                      ...     ...   \n",
            "132795         NaN  EMERGENCY RESPONSE TEAM  2010Q1   \n",
            "132796         NaN  EMERGENCY RESPONSE TEAM  2010Q1   \n",
            "132797         NaN  EMERGENCY RESPONSE TEAM  2010Q1   \n",
            "132798         NaN  EMERGENCY RESPONSE TEAM  2010Q1   \n",
            "132799         NaN  EMERGENCY RESPONSE TEAM  2010Q1   \n",
            "\n",
            "                              CATEGORY  DATE  \\\n",
            "0                       OTHER SERVICES   NaN   \n",
            "1               SUPPLIES AND MATERIALS   NaN   \n",
            "2               SUPPLIES AND MATERIALS   NaN   \n",
            "3               SUPPLIES AND MATERIALS   NaN   \n",
            "4               SUPPLIES AND MATERIALS   NaN   \n",
            "...                                ...   ...   \n",
            "132795                          TRAVEL   NaN   \n",
            "132796                          TRAVEL   NaN   \n",
            "132797  RENT, COMMUNICATION, UTILITIES   NaN   \n",
            "132798  RENT, COMMUNICATION, UTILITIES   NaN   \n",
            "132799                  OTHER SERVICES   NaN   \n",
            "\n",
            "                                                    PAYEE START DATE  \\\n",
            "0       03Â­10       P2 MFP0003226                    ...   03/02/10   \n",
            "1            02Â­05       P2    MFP0003219       ALLSTEEL   11/28/09   \n",
            "2       03Â­05       P2    OSM42304         CDW GOVERN...   12/21/09   \n",
            "3             03Â­05       P2    OSM42304              DO   12/21/09   \n",
            "4             03Â­05       P2    OSM42304              DO   12/21/09   \n",
            "...                                                   ...        ...   \n",
            "132795  03Â­29   P1   10A54000097               KEVIN ...   02/14/10   \n",
            "132796  03Â­29   P1   10A54000096               PAUL J...   02/14/10   \n",
            "132797        03Â­07   P1 10A10600093     RICHARD MARTINS   02/14/10   \n",
            "132798         03Â­07   P1 10A10600097     TIMOTHY WRIGHT   02/14/10   \n",
            "132799  03Â­07   P1 10A60200014                 DANIEL...   02/24/10   \n",
            "\n",
            "        END DATE                         PURPOSE  AMOUNT              YEAR  \\\n",
            "0       03/02/10  NON-TECHNOLOGY SERVICE CONTRCT  455.00  FISCAL YEAR 2010   \n",
            "1       11/28/09             HABITATION EXPENSES   47.26  FISCAL YEAR 2010   \n",
            "2       12/21/09         OFFICE SUPPLIES OUTSIDE  250.00  FISCAL YEAR 2010   \n",
            "3       12/21/09         OFFICE SUPPLIES OUTSIDE  436.00  FISCAL YEAR 2010   \n",
            "4       12/21/09         OFFICE SUPPLIES OUTSIDE   37.90  FISCAL YEAR 2010   \n",
            "...          ...                             ...     ...               ...   \n",
            "132795  02/19/10            TRAVEL REIMBURSEMENT  858.00  FISCAL YEAR 2010   \n",
            "132796  02/19/10            TRAVEL REIMBURSEMENT  795.00  FISCAL YEAR 2010   \n",
            "132797  02/19/10      TELECOM SVC, EQUIP & TOLLS    9.95  FISCAL YEAR 2010   \n",
            "132798  02/19/10      TELECOM SVC, EQUIP & TOLLS   19.90  FISCAL YEAR 2010   \n",
            "132799  03/02/10   JANITORIAL & MAINTENANCE SVCS  295.11  FISCAL YEAR 2010   \n",
            "\n",
            "        TRANSCODE  TRANSCODELONG  RECORDID  \\\n",
            "0             NaN            NaN       NaN   \n",
            "1             NaN            NaN       NaN   \n",
            "2             NaN            NaN       NaN   \n",
            "3             NaN            NaN       NaN   \n",
            "4             NaN            NaN       NaN   \n",
            "...           ...            ...       ...   \n",
            "132795        NaN            NaN       NaN   \n",
            "132796        NaN            NaN       NaN   \n",
            "132797        NaN            NaN       NaN   \n",
            "132798        NaN            NaN       NaN   \n",
            "132799        NaN            NaN       NaN   \n",
            "\n",
            "                                            RECIP (orig.)  \n",
            "0       03Â­10       P2 MFP0003226                    ...  \n",
            "1            02Â­05       P2    MFP0003219       ALLSTEEL  \n",
            "2       03Â­05       P2    OSM42304         CDW GOVERN...  \n",
            "3             03Â­05       P2    OSM42304              DO  \n",
            "4             03Â­05       P2    OSM42304              DO  \n",
            "...                                                   ...  \n",
            "132795  03Â­29   P1   10A54000097               KEVIN ...  \n",
            "132796  03Â­29   P1   10A54000096               PAUL J...  \n",
            "132797        03Â­07   P1 10A10600093     RICHARD MARTINS  \n",
            "132798         03Â­07   P1 10A10600097     TIMOTHY WRIGHT  \n",
            "132799  03Â­07   P1 10A60200014                 DANIEL...  \n",
            "\n",
            "[132800 rows x 15 columns]\n"
          ]
        }
      ],
      "source": [
        "### Write your code below this comment.\n",
        "\n",
        "path = '/content/'\n",
        "\n",
        "files = glob.glob(path + \"/*.csv\")\n",
        "df_1 = {'detail': {}, 'summary': {}}\n",
        "\n",
        "for file in files:\n",
        "\n",
        "    match = re.search(r'(\\d{4}Q\\d)', file)\n",
        "    if match:\n",
        "        year_quarter = match.group(1)\n",
        "    else:\n",
        "\n",
        "        continue\n",
        "\n",
        "\n",
        "    data_type = 'detail' if 'detail' in file else 'summary'\n",
        "\n",
        "\n",
        "    key = f'Y{year_quarter}'\n",
        "\n",
        "\n",
        "    df = pd.read_csv(file, encoding='unicode_escape', low_memory=False)\n",
        "\n",
        "\n",
        "    df.columns = df.columns.str.strip().str.lstrip()\n",
        "\n",
        "\n",
        "    df_1[data_type][key] = df\n",
        "\n",
        "\n",
        "print(df_1['detail']['Y2010Q1'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After updating above is the updated columns"
      ],
      "metadata": {
        "id": "R8PtQnkoswTp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzicgcofH6Oc"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irynFQnnH6Od"
      },
      "source": [
        "### Task 3 (3 marks)\n",
        "\n",
        "1. Combine all the `'detail'` Dataframes from your store vertically into a single Dataframe named __df_detail__ based on common columns across all the Dataframes.\n",
        "2. Make sure the sort order of the common column names is the same as that in the first Dataframe `data['detail']['Y2010Q1']`.\n",
        "3. Once you have done that, confirm whether the total number of rows for all the Dataframes is equal to the number of rows for the combined Dataframe __df_detail__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5sE6t8oH6Od",
        "outputId": "3ebb2ce1-0809-4452-b274-1d4bd77107b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        BIOGUIDE_ID                      OFFICE QUARTER  \\\n",
            "0               NaN  2017 OFFICE OF THE SPEAKER  2017Q2   \n",
            "1               NaN  2017 OFFICE OF THE SPEAKER  2017Q2   \n",
            "2               NaN  2017 OFFICE OF THE SPEAKER  2017Q2   \n",
            "3               NaN  2017 OFFICE OF THE SPEAKER  2017Q2   \n",
            "4               NaN  2017 OFFICE OF THE SPEAKER  2017Q2   \n",
            "...             ...                         ...     ...   \n",
            "3289983         NaN                SUPPORT TEAM  2010Q3   \n",
            "3289984         NaN                SUPPORT TEAM  2010Q3   \n",
            "3289985         NaN                SUPPORT TEAM  2010Q3   \n",
            "3289986         NaN                SUPPORT TEAM  2010Q3   \n",
            "3289987         NaN                SUPPORT TEAM  2010Q3   \n",
            "\n",
            "                       CATEGORY        DATE                      PAYEE  \\\n",
            "0        PERSONNEL COMPENSATION                      ALTHOUSE JOSHUA S   \n",
            "1        PERSONNEL COMPENSATION                       ANDRES DOUGLAS R   \n",
            "2        PERSONNEL COMPENSATION                       ANDREWS THOMAS S   \n",
            "3        PERSONNEL COMPENSATION                        ANTELL GEOFFREY   \n",
            "4        PERSONNEL COMPENSATION                    BENJAMIN WILLIAM C.   \n",
            "...                         ...         ...                        ...   \n",
            "3289983                  TRAVEL  2019-07-12          WRIGHT, TIMOTHY D   \n",
            "3289984                  TRAVEL  2019-07-28           MARTINS, RICHARD   \n",
            "3289985                  TRAVEL  2019-07-28           MARTINS, RICHARD   \n",
            "3289986                  TRAVEL  2019-07-28           MARTINS, RICHARD   \n",
            "3289987  SUPPLIES AND MATERIALS  2019-08-17  CITIBANK GOV CARD SERVICE   \n",
            "\n",
            "         START DATE    END DATE                         PURPOSE    AMOUNT  \\\n",
            "0        2017-04-01  2017-06-30  CONSERVATIVE OUTREACH DIRECTOR  20000.01   \n",
            "1        2017-04-01  2017-06-30                 PRESS SECRETARY  27500.01   \n",
            "2        2017-04-01  2017-06-30        MEMBER SERVICES DIRECTOR   32500.0   \n",
            "3        2017-04-01  2017-06-30  ASST TO THE SPEAKER FOR POLICY   41250.0   \n",
            "4        2017-04-01  2017-06-30            SYSTEM ADMINISTRATOR  13250.01   \n",
            "...             ...         ...                             ...       ...   \n",
            "3289983  2010-06-20  2010-06-23                           MEALS        69   \n",
            "3289984  2010-06-22  2010-06-23                           MEALS        69   \n",
            "3289985  2010-06-22  2010-06-23                         LODGING    103.68   \n",
            "3289986  2010-06-22  2010-06-23   PRIVATE OWNED VEHICLE MILEAGE        45   \n",
            "3289987  2010-05-29  2010-06-28         OFFICE SUPPLIES OUTSIDE  2,793.93   \n",
            "\n",
            "                     YEAR TRANSCODE  \\\n",
            "0                    2017             \n",
            "1                    2017             \n",
            "2                    2017             \n",
            "3                    2017             \n",
            "4                    2017             \n",
            "...                   ...       ...   \n",
            "3289983  FISCAL YEAR 2010        P1   \n",
            "3289984  FISCAL YEAR 2010        P1   \n",
            "3289985  FISCAL YEAR 2010        P1   \n",
            "3289986  FISCAL YEAR 2010        P1   \n",
            "3289987  FISCAL YEAR 2010        P1   \n",
            "\n",
            "                                             TRANSCODELONG     RECORDID  \\\n",
            "0                                                      NaN          NaN   \n",
            "1                                                      NaN          NaN   \n",
            "2                                                      NaN          NaN   \n",
            "3                                                      NaN          NaN   \n",
            "4                                                      NaN          NaN   \n",
            "...                                                    ...          ...   \n",
            "3289983  Payment/reimbursement requested on a standard ...  10A00600007   \n",
            "3289984  Payment/reimbursement requested on a standard ...  10A10600237   \n",
            "3289985  Payment/reimbursement requested on a standard ...  10A10600238   \n",
            "3289986  Payment/reimbursement requested on a standard ...  10A10600239   \n",
            "3289987  Payment/reimbursement requested on a standard ...  10A11800121   \n",
            "\n",
            "                     RECIP (orig.)  \n",
            "0                              NaN  \n",
            "1                              NaN  \n",
            "2                              NaN  \n",
            "3                              NaN  \n",
            "4                              NaN  \n",
            "...                            ...  \n",
            "3289983                         DO  \n",
            "3289984           MARTINS, RICHARD  \n",
            "3289985                         DO  \n",
            "3289986                         DO  \n",
            "3289987  CITIBANK GOV CARD SERVICE  \n",
            "\n",
            "[3289988 rows x 15 columns]\n"
          ]
        }
      ],
      "source": [
        "### Write your code below this comment.\n",
        "\n",
        "common_columns = df_1['detail']['Y2010Q1'].columns\n",
        "\n",
        "df_detail = pd.DataFrame(columns=common_columns)\n",
        "\n",
        "for key, df in df_1['detail'].items():\n",
        "    common_columns_in_df = common_columns.intersection(df.columns)\n",
        "    df_detail = pd.concat([df_detail, df[common_columns_in_df]], ignore_index=True)\n",
        "\n",
        "print(df_detail)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_rows_detail = sum(df.shape[0] for df in df_1['detail'].values())\n",
        "print(f'Total number of rows is: {total_rows_detail}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKgYlVjKN1IV",
        "outputId": "61f9ef54-191a-4008-c40e-7b773c67a61b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of rows is: 3289988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_detail.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BBUHbuhON7t",
        "outputId": "2e2f270b-ac18-4edc-8644-56893d949798"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3289988"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above both are equal."
      ],
      "metadata": {
        "id": "HtpBXJ-BOW1o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQDwLlG-H6Od"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1fDjUNGH6Od"
      },
      "source": [
        "### Task 4 (3 marks)\n",
        "\n",
        "1. Similarly, combine all the `'summary'` Dataframes from your store vertically into a single Dataframe named __df_summary__ based on common columns across all the Dataframes.\n",
        "2. Make sure the sort order of the common column names is the same as that in the first Dataframe `data['summary']['Y2010Q1']`.\n",
        "3. Once you have done that, confirm whether the total number of rows for all the Dataframes is equal to the number of rows for the combined Dataframe __df_summary__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3vNFIsUH6Od",
        "outputId": "7bcf5687-cd07-4713-8a1e-ba6f579770c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  BIOGUIDE_ID                 OFFICE  YEAR QUARTER  \\\n",
            "0         NaN  OFFICE OF THE SPEAKER  2014  2014Q3   \n",
            "1         NaN  OFFICE OF THE SPEAKER  2014  2014Q3   \n",
            "2         NaN  OFFICE OF THE SPEAKER  2014  2014Q3   \n",
            "3         NaN  OFFICE OF THE SPEAKER  2014  2014Q3   \n",
            "4         NaN  OFFICE OF THE SPEAKER  2014  2014Q3   \n",
            "\n",
            "                         CATEGORY           YTD        AMOUNT  \n",
            "0              PERSONNEL BENEFITS     18,749.97      6,249.99  \n",
            "1          PERSONNEL COMPENSATION  4,271,532.94  1,509,413.26  \n",
            "2                          TRAVEL      9,622.60      2,552.03  \n",
            "3  RENT, COMMUNICATION, UTILITIES        232.61          0.00  \n",
            "4       PRINTING AND REPRODUCTION      3,181.90      1,239.20  \n"
          ]
        }
      ],
      "source": [
        "### Write your code below this comment.\n",
        "common_columns_summary = df_1['summary']['Y2010Q1'].columns\n",
        "\n",
        "df_summary = pd.DataFrame(columns=common_columns_summary)\n",
        "\n",
        "\n",
        "for key, df in df_1['summary'].items():\n",
        "\n",
        "    common_columns_in_df_summary = common_columns_summary.intersection(df.columns)\n",
        "    df_summary = pd.concat([df_summary, df[common_columns_in_df_summary]], ignore_index=True)\n",
        "\n",
        "\n",
        "print(df_summary.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_rows_summary = sum(df.shape[0] for df in df_1['summary'].values())\n",
        "print(f'Total number of rows in summary is {total_rows_summary} and in dataframe is {df_summary.shape[0]}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF2160L_Ow_a",
        "outputId": "845ddbbc-49ab-44df-f0cd-e6dd971305d0"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of rows in summary is 134904 and in dataframe is 134904.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above they seem equal."
      ],
      "metadata": {
        "id": "0rOZSJfGO89G"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFhm9JTBH6Od"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YepPnlieH6Od"
      },
      "source": [
        "### Task 5 (1.5 marks)\n",
        "\n",
        "1. Find missing values in the __df_detail__ Dataframe and report the sum of missing values for all the columns in __df_detail__ as a single number.\n",
        "2. Note that the combined Dataframe __df_detail__ would have some columns that have 3 spaces `'   '` stored as a string which came from the 2017 data files and basically indicate a missing value. Convert these values to __NaN__ so they are correctly recognized as missing values.\n",
        "3. Then update the count of missing values again as a single number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNeJzqxKH6Od",
        "outputId": "d425069c-5da2-4b9a-e619-1a47beb2da29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of missing values before conversion: 4727603\n",
            "Sum of missing values after conversion: 4791647\n"
          ]
        }
      ],
      "source": [
        "### Write your code below this comment.\n",
        "import numpy as np\n",
        "\n",
        "na_before = df_detail.isnull().sum().sum()\n",
        "print(f\"Sum of missing values before conversion: {na_before}\")\n",
        "\n",
        "\n",
        "df_detail.replace(' ', np.nan, inplace=True)\n",
        "\n",
        "na_after = df_detail.isnull().sum().sum()\n",
        "print(f\"Sum of missing values after conversion: {na_after}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZGyqh_CH6Od"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hz9EmhLH6Oe"
      },
      "source": [
        "### Task 6 (1.5 marks)\n",
        "\n",
        "Specify the right data type for the following columns in __df_detail__ for further analysis:\n",
        "\n",
        "- `'AMOUNT'`\n",
        "- `'START DATE'`\n",
        "- `'END DATE'`\n",
        "\n",
        "The __AMOUNT__ column needs to be converted into a numeric column (i.e. one with floating point values). While the columns __START DATE__ and __END DATE__ need to be converted into DateTime type objects. Make sure you handle the commas in the __AMOUNT__ column before converting it into numeric type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckfivQwgH6Oe"
      },
      "source": [
        "<u>Hint:</u> If you get any errors, try using `errors=\"coerce\"` and that should do the trick."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wgkd_5qJH6Oe",
        "outputId": "0af9af15-4996-4f75-ce6c-938f9042077e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BIOGUIDE_ID              object\n",
            "OFFICE                   object\n",
            "QUARTER                  object\n",
            "CATEGORY                 object\n",
            "DATE                     object\n",
            "PAYEE                    object\n",
            "START DATE       datetime64[ns]\n",
            "END DATE         datetime64[ns]\n",
            "PURPOSE                  object\n",
            "AMOUNT                  float64\n",
            "YEAR                     object\n",
            "TRANSCODE                object\n",
            "TRANSCODELONG            object\n",
            "RECORDID                 object\n",
            "RECIP (orig.)            object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "### Write your code below this comment.\n",
        "\n",
        "df_detail['AMOUNT'] = pd.to_numeric(df_detail['AMOUNT'], errors='coerce')\n",
        "df_detail['START DATE'] = pd.to_datetime(df_detail['START DATE'], errors='coerce')\n",
        "df_detail['END DATE'] = pd.to_datetime(df_detail['END DATE'], errors='coerce')\n",
        "\n",
        "\n",
        "print(df_detail.dtypes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OA8KaSYH6Oe"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d1ZxMaVH6Oe"
      },
      "source": [
        "### NOW ANSWER THE FOLLOWING QUESTIONS.\n",
        "\n",
        "All questions pertain to the __df_detail__ Dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cgFdUrdH6Oe"
      },
      "source": [
        "<u>Note:</u> The detailed instructions you have received in this exam so far regarding transformations were for your convenience only. In a real-world Data Science challenge, you would only be asked the questions (such as the ones to follow) and then it's up to you to do whatever transformations need to be done to answer those questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QIMpXTmH6Oe"
      },
      "source": [
        "### Task 7 (1 mark)\n",
        "\n",
        "What is the total of all the payments in the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edQEo422H6Oe",
        "outputId": "fca7c56b-c302-4b50-bc7d-0997af05eda7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total of all payments is 4701011813.839999.\n"
          ]
        }
      ],
      "source": [
        "### Write your code below this comment.\n",
        "pay_total = df_detail['AMOUNT'].sum()\n",
        "\n",
        "print(f'Total of all payments is {pay_total}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JxjYbCiH6Oe"
      },
      "source": [
        "### Task 8 (2 marks)\n",
        "\n",
        "What was the average annual expenditure with a __START DATE__ date between January 1, 2010 and December 31, 2016 (inclusive)? Only consider payments with strictly positive amounts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhodjSQAH6Oe",
        "outputId": "a76ec2cf-d236-4cb0-d964-7d37b848f423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average annual expenditure between 2010 and 2016 (inclusive) is 127537074.9299999.\n"
          ]
        }
      ],
      "source": [
        "### Write your code below this comment.\n",
        "\n",
        "df_1_filter = df_detail[(df_detail['START DATE'] >= '2010-01-01') & (df_detail['START DATE'] <= '2016-12-31') & (df_detail['AMOUNT'] > 0)]\n",
        "\n",
        "df1_avg_exp = df_1_filter['AMOUNT'].sum() / len(df_1_filter['START DATE'].dt.year.unique())\n",
        "\n",
        "print(f'The average annual expenditure between 2010 and 2016 (inclusive) is {df1_avg_exp}.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hydULs5IH6Of"
      },
      "source": [
        "### Task 9 (2 marks)\n",
        "\n",
        "What was the highest average staff salary among all representatives in 2016? Assume staff size is equal to the number of unique payees in the `'PERSONNEL COMPENSATION'` category for each representative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2Qj5RdPH6Of",
        "outputId": "6f414c4f-576a-4e05-b8e8-b1a948ad7982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The highest average salary is 50970.33.\n"
          ]
        }
      ],
      "source": [
        "### Write your code below this comment.\n",
        "\n",
        "df_2016 = df_detail[(df_detail['START DATE'].dt.year == 2016) & (df_detail['CATEGORY'] == 'PERSONNEL COMPENSATION')]\n",
        "rep_2016 = df_2016.groupby('PAYEE').agg({'AMOUNT': 'mean', 'PAYEE': 'nunique'})\n",
        "rep_2016['Average Salary per Staff'] = rep_2016['AMOUNT']\n",
        "highest_average_salary = rep_2016['Average Salary per Staff'].max()\n",
        "\n",
        "print(f'The highest average salary is {highest_average_salary}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqzu7WT1H6Of"
      },
      "source": [
        "### Task 10 (3 marks)\n",
        "\n",
        "1. Find the __OFFICE__ with the highest total expenditures with a __START DATE__ in 2016.\n",
        "2. For this office, find the __PURPOSE__ that accounts for the highest total expenditures.\n",
        "3. What fraction of the total expenditures (all records, all offices) with a __START DATE__ in 2016 do these expenditures amount to?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPLHqERuH6Of",
        "outputId": "435d16a8-3f95-48f0-8336-c248c3ce0abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Office with the highest total expenditures in 2016 is GOVERNMENT CONTRIBUTIONS with purpose that accounts for highest total exp is FERS.\n",
            "Total expenditures for the identified office and purpose is 115030831.70999998 with a fraction 0.0245 of total expenditures.\n"
          ]
        }
      ],
      "source": [
        "### Write your code below this comment.\n",
        "\n",
        "df_2016 = df_detail[df_detail['START DATE'].dt.year == 2016]\n",
        "office_total_expenditures_2016 = df_2016.groupby('OFFICE')['AMOUNT'].sum()\n",
        "ofc_hg_exp_2016 = office_total_expenditures_2016.idxmax()\n",
        "df_ofc_hg_exp_2016 = df_2016[df_2016['OFFICE'] == ofc_hg_exp_2016]\n",
        "\n",
        "pp_total_exp = df_ofc_hg_exp_2016.groupby('PURPOSE')['AMOUNT'].sum()\n",
        "pp_hg_exp = pp_total_exp.idxmax()\n",
        "total_exp_ofc_pp = df_ofc_hg_exp_2016['AMOUNT'].sum()\n",
        "fraction_exp_ofc_pp = total_exp_ofc_pp / df_detail['AMOUNT'].sum()\n",
        "\n",
        "print(f'Office with the highest total expenditures in 2016 is {ofc_hg_exp_2016} with purpose that accounts for highest total exp is {pp_hg_exp}.')\n",
        "print(f'Total expenditures for the identified office and purpose is {total_exp_ofc_pp} with a fraction {fraction_exp_ofc_pp:.4f} of total expenditures.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}